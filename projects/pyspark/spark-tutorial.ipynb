{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Spark Tutorial](https://www.youtube.com/watch?v=5RosqOeJrrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# `local[*]` means use all available cores on the local machine.\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-intro\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3e6699c11a7b:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark-intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc63f7ecc50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of driver cores.\n",
    "\n",
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n",
      "Number of rows in the Employees DataFrame: 20\n",
      "Number of partitions in the Employees DataFrame: 1\n"
     ]
    }
   ],
   "source": [
    "# Read csv into dataframe\n",
    "\n",
    "emp = spark.read.csv('data/emp.csv', header=True, inferSchema=True)\n",
    "emp.show()\n",
    "\n",
    "print(f\"Number of rows in the Employees DataFrame: {emp.count()}\")\n",
    "print(f\"Number of partitions in the Employees DataFrame: {emp.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- hire_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the dataframe\n",
    "\n",
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the number of partitions to 10\n",
    "# (use `coalesce()` to decrease the number of partitions)\n",
    "\n",
    "emp_re = emp.repartition(10)\n",
    "emp_re.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n",
      "Number of rows in the Employees (Repartitioned) DataFrame: 20\n",
      "Number of partitions in the Employees (Repartitioned) DataFrame: 10\n"
     ]
    }
   ],
   "source": [
    "emp_re.show()\n",
    "\n",
    "print(f\"Number of rows in the Employees (Repartitioned) DataFrame: {emp_re.count()}\")\n",
    "print(f\"Number of partitions in the Employees (Repartitioned) DataFrame: {emp_re.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the Cities-DataFrame: 2349391\n",
      "Number of partitions in the Cities-DataFrame: 19\n"
     ]
    }
   ],
   "source": [
    "# Load another (much larger) csv into a new dataframe and check its properties.\n",
    "\n",
    "cities = spark.read.csv('data/cities.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Print the rows and partitions of the dataframe\n",
    "print(f\"Number of rows in the Cities-DataFrame: {cities.count()}\")\n",
    "print(f\"Number of partitions in the Cities-DataFrame: {cities.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Transformations 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('employee_id', IntegerType(), True), StructField('department_id', IntegerType(), True), StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('gender', StringType(), True), StructField('salary', IntegerType(), True), StructField('hire_date', TimestampType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])\n",
      "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])\n"
     ]
    }
   ],
   "source": [
    "# Creating a manual schema in Spark\n",
    "from pyspark.sql.types import _parse_datatype_string\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# ! IMPLICT INFERENCE\n",
    "# Spark can infer the schema from a string\n",
    "schema_string = \"name string, age int\"\n",
    "print(_parse_datatype_string(schema_string))\n",
    "\n",
    "# ! EXPLICIT INFERENCE\n",
    "# Template: StructType([StructField(name, dataType, nullable?)]) \n",
    "schema_spark = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "print(schema_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+\n",
      "|employee_id|         name|age|salary|\n",
      "+-----------+-------------+---+------+\n",
      "|          1|     John Doe| 30| 50000|\n",
      "|          2|   Jane Smith| 25| 45000|\n",
      "|          3|    Bob Brown| 35| 55000|\n",
      "|          4|    Alice Lee| 28| 48000|\n",
      "|          5|    Jack Chan| 40| 60000|\n",
      "|          6|    Jill Wong| 32| 52000|\n",
      "|          7|James Johnson| 42| 70000|\n",
      "|          8|     Kate Kim| 29| 51000|\n",
      "|          9|      Tom Tan| 33| 58000|\n",
      "|         10|     Lisa Lee| 27| 47000|\n",
      "|         11|   David Park| 38| 65000|\n",
      "|         12|   Susan Chen| 31| 54000|\n",
      "|         13|    Brian Kim| 45| 75000|\n",
      "|         14|    Emily Lee| 26| 46000|\n",
      "|         15|  Michael Lee| 37| 63000|\n",
      "|         16|  Kelly Zhang| 30| 49000|\n",
      "|         17|  George Wang| 34| 57000|\n",
      "|         18|    Nancy Liu| 29| 50000|\n",
      "|         19|  Steven Chen| 36| 62000|\n",
      "|         20|    Grace Kim| 32| 53000|\n",
      "+-----------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Columns and Expressions\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# ? col(\"name\") == expr(\"name\"), since both are Column objects and hence treated as same.\n",
    "# select employee_id, name, age, salary from emp\n",
    "\n",
    "emp_filtered = emp.select(col(\"employee_id\"), expr(\"name\"), emp.age, emp.salary)    # ! TRANSFORMATION\n",
    "emp_filtered.show() # ! ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     1|     John Doe| 30| 50000|\n",
      "|     2|   Jane Smith| 25| 45000|\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     4|    Alice Lee| 28| 48000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     8|     Kate Kim| 29| 51000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    10|     Lisa Lee| 27| 47000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    14|    Emily Lee| 26| 46000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    16|  Kelly Zhang| 30| 49000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    18|    Nancy Liu| 29| 50000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted = emp_filtered.select(expr(\"employee_id as emp_id\"), emp_filtered.name, expr(\"cast(age as int) as age\"), emp_filtered.salary)\n",
    "emp_casted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     1|     John Doe| 30| 50000|\n",
      "|     2|   Jane Smith| 25| 45000|\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     4|    Alice Lee| 28| 48000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     8|     Kate Kim| 29| 51000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    10|     Lisa Lee| 27| 47000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    14|    Emily Lee| 26| 46000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    16|  Kelly Zhang| 30| 49000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    18|    Nancy Liu| 29| 50000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted_alt = emp_filtered.selectExpr(\"employee_id as emp_id\", \"name\", \"cast(age as int) as age\", \"salary\")\n",
    "emp_casted_alt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter emp_casted based on Age > 30\n",
    "\n",
    "emp_casted.select(\"emp_id\", \"name\", \"age\", \"salary\").where(\"age > 30\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Transformations 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- hire_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, cast\n",
    "\n",
    "emp.select(\"employee_id\", \"name\", \"age\", col(\"salary\").cast(\"double\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "|         11|   David Park| 38|65000.0|13000.0|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding new columns to the DataFrame\n",
    "\n",
    "emp_casted = emp.select(\"employee_id\", \"name\", \"age\", col(\"salary\").cast(\"double\"))\n",
    "\n",
    "emp_taxed = emp_casted.withColumn(\"tax\", col(\"salary\") * 0.2)\n",
    "emp_taxed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Literals (Adding a constant to the DataFrame)\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "emp_new_cols = emp_taxed.withColumn(\"columnOne\", lit(1)).withColumn(\"columnTwo\", lit(\"two\"))\n",
    "emp_new_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|emp_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|     1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|     2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|     3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|     4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|     5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|     6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|     7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|     8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|     9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|    10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|    11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|    12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|    13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|    14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|    15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|    16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|    17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|    18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|    19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|    20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_new_cols.withColumnRenamed(\"employee_id\", \"emp_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|\n",
      "+-----------+-------------+---+-------+-------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|\n",
      "+-----------+-------------+---+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns from the DataFrame\n",
    "\n",
    "emp_new_cols.drop(\"columnTwo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_new_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrame where tax > 10000, along with LIMIT to 5 rows\n",
    "\n",
    "emp_taxed.where(\"tax > 10000\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+------+\n",
      "|employee_id|         name|age| salary|    tax| bonus|\n",
      "+-----------+-------------+---+-------+-------+------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|5000.0|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|4500.0|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|5500.0|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|4800.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|6000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|5200.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|7000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|5100.0|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|5800.0|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|4700.0|\n",
      "|         11|   David Park| 38|65000.0|13000.0|6500.0|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|5400.0|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|7500.0|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|4600.0|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|6300.0|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|4900.0|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|5700.0|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|5000.0|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|6200.0|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|5300.0|\n",
      "+-----------+-------------+---+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bonus: Adding multiple columns to the dataframe at once\n",
    "\n",
    "columns = {\n",
    "    'tax': col('salary') * 0.2,\n",
    "    'bonus': col('salary') * 0.1\n",
    "}\n",
    "\n",
    "emp_casted.withColumns(columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
