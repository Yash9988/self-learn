{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Spark Tutorial](https://www.youtube.com/watch?v=5RosqOeJrrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# `local[*]` means use all available cores on the local machine.\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-intro\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3e6699c11a7b:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark-intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc63f7ecc50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of driver cores.\n",
    "\n",
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n",
      "Number of rows in the Employees DataFrame: 20\n",
      "Number of partitions in the Employees DataFrame: 1\n"
     ]
    }
   ],
   "source": [
    "# Read csv into dataframe\n",
    "\n",
    "emp = spark.read.csv('data/emp.csv', header=True, inferSchema=True)\n",
    "emp.show()\n",
    "\n",
    "print(f\"Number of rows in the Employees DataFrame: {emp.count()}\")\n",
    "print(f\"Number of partitions in the Employees DataFrame: {emp.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- hire_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the dataframe\n",
    "\n",
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the number of partitions to 10\n",
    "# (use `coalesce()` to decrease the number of partitions)\n",
    "\n",
    "emp_re = emp.repartition(10)\n",
    "emp_re.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n",
      "Number of rows in the Employees (Repartitioned) DataFrame: 20\n",
      "Number of partitions in the Employees (Repartitioned) DataFrame: 10\n"
     ]
    }
   ],
   "source": [
    "emp_re.show()\n",
    "\n",
    "print(f\"Number of rows in the Employees (Repartitioned) DataFrame: {emp_re.count()}\")\n",
    "print(f\"Number of partitions in the Employees (Repartitioned) DataFrame: {emp_re.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the Cities-DataFrame: 2349391\n",
      "Number of partitions in the Cities-DataFrame: 19\n"
     ]
    }
   ],
   "source": [
    "# Load another (much larger) csv into a new dataframe and check its properties.\n",
    "\n",
    "cities = spark.read.csv('data/cities.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Print the rows and partitions of the dataframe\n",
    "print(f\"Number of rows in the Cities-DataFrame: {cities.count()}\")\n",
    "print(f\"Number of partitions in the Cities-DataFrame: {cities.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Transformations 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('employee_id', IntegerType(), True), StructField('department_id', IntegerType(), True), StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('gender', StringType(), True), StructField('salary', IntegerType(), True), StructField('hire_date', TimestampType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])\n",
      "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])\n"
     ]
    }
   ],
   "source": [
    "# Creating a manual schema in Spark\n",
    "from pyspark.sql.types import _parse_datatype_string\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# ! IMPLICT INFERENCE\n",
    "# Spark can infer the schema from a string\n",
    "schema_string = \"name string, age int\"\n",
    "print(_parse_datatype_string(schema_string))\n",
    "\n",
    "# ! EXPLICIT INFERENCE\n",
    "# Template: StructType([StructField(name, dataType, nullable?)]) \n",
    "schema_spark = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "print(schema_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+------+\n",
      "|employee_id|         name|age|salary|\n",
      "+-----------+-------------+---+------+\n",
      "|          1|     John Doe| 30| 50000|\n",
      "|          2|   Jane Smith| 25| 45000|\n",
      "|          3|    Bob Brown| 35| 55000|\n",
      "|          4|    Alice Lee| 28| 48000|\n",
      "|          5|    Jack Chan| 40| 60000|\n",
      "|          6|    Jill Wong| 32| 52000|\n",
      "|          7|James Johnson| 42| 70000|\n",
      "|          8|     Kate Kim| 29| 51000|\n",
      "|          9|      Tom Tan| 33| 58000|\n",
      "|         10|     Lisa Lee| 27| 47000|\n",
      "|         11|   David Park| 38| 65000|\n",
      "|         12|   Susan Chen| 31| 54000|\n",
      "|         13|    Brian Kim| 45| 75000|\n",
      "|         14|    Emily Lee| 26| 46000|\n",
      "|         15|  Michael Lee| 37| 63000|\n",
      "|         16|  Kelly Zhang| 30| 49000|\n",
      "|         17|  George Wang| 34| 57000|\n",
      "|         18|    Nancy Liu| 29| 50000|\n",
      "|         19|  Steven Chen| 36| 62000|\n",
      "|         20|    Grace Kim| 32| 53000|\n",
      "+-----------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Columns and Expressions\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# ? col(\"name\") == expr(\"name\"), since both are Column objects and hence treated as same.\n",
    "# select employee_id, name, age, salary from emp\n",
    "\n",
    "emp_filtered = emp.select(col(\"employee_id\"), expr(\"name\"), emp.age, emp.salary)    # ! TRANSFORMATION\n",
    "emp_filtered.show() # ! ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     1|     John Doe| 30| 50000|\n",
      "|     2|   Jane Smith| 25| 45000|\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     4|    Alice Lee| 28| 48000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     8|     Kate Kim| 29| 51000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    10|     Lisa Lee| 27| 47000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    14|    Emily Lee| 26| 46000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    16|  Kelly Zhang| 30| 49000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    18|    Nancy Liu| 29| 50000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted = emp_filtered.select(expr(\"employee_id as emp_id\"), emp_filtered.name, expr(\"cast(age as int) as age\"), emp_filtered.salary)\n",
    "emp_casted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     1|     John Doe| 30| 50000|\n",
      "|     2|   Jane Smith| 25| 45000|\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     4|    Alice Lee| 28| 48000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     8|     Kate Kim| 29| 51000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    10|     Lisa Lee| 27| 47000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    14|    Emily Lee| 26| 46000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    16|  Kelly Zhang| 30| 49000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    18|    Nancy Liu| 29| 50000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_casted_alt = emp_filtered.selectExpr(\"employee_id as emp_id\", \"name\", \"cast(age as int) as age\", \"salary\")\n",
    "emp_casted_alt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------+\n",
      "|emp_id|         name|age|salary|\n",
      "+------+-------------+---+------+\n",
      "|     3|    Bob Brown| 35| 55000|\n",
      "|     5|    Jack Chan| 40| 60000|\n",
      "|     6|    Jill Wong| 32| 52000|\n",
      "|     7|James Johnson| 42| 70000|\n",
      "|     9|      Tom Tan| 33| 58000|\n",
      "|    11|   David Park| 38| 65000|\n",
      "|    12|   Susan Chen| 31| 54000|\n",
      "|    13|    Brian Kim| 45| 75000|\n",
      "|    15|  Michael Lee| 37| 63000|\n",
      "|    17|  George Wang| 34| 57000|\n",
      "|    19|  Steven Chen| 36| 62000|\n",
      "|    20|    Grace Kim| 32| 53000|\n",
      "+------+-------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter emp_casted based on Age > 30\n",
    "\n",
    "emp_casted.select(\"emp_id\", \"name\", \"age\", \"salary\").where(\"age > 30\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Transformations 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- hire_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, cast\n",
    "\n",
    "emp.select(\"employee_id\", \"name\", \"age\", col(\"salary\").cast(\"double\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "|         11|   David Park| 38|65000.0|13000.0|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding new columns to the DataFrame\n",
    "\n",
    "emp_casted = emp.select(\"employee_id\", \"name\", \"age\", col(\"salary\").cast(\"double\"))\n",
    "\n",
    "emp_taxed = emp_casted.withColumn(\"tax\", col(\"salary\") * 0.2)\n",
    "emp_taxed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Literals (Adding a constant to the DataFrame)\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "emp_new_cols = emp_taxed.withColumn(\"columnOne\", lit(1)).withColumn(\"columnTwo\", lit(\"two\"))\n",
    "emp_new_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|emp_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "|     1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|     2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|     3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|     4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|     5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|     6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|     7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|     8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|     9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|    10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|    11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|    12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|    13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|    14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|    15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|    16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|    17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|    18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|    19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|    20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_new_cols.withColumnRenamed(\"employee_id\", \"emp_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|\n",
      "+-----------+-------------+---+-------+-------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|\n",
      "+-----------+-------------+---+-------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns from the DataFrame\n",
    "\n",
    "emp_new_cols.drop(\"columnTwo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|employee_id|         name|age| salary|    tax|columnOne|columnTwo|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|        1|      two|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|        1|      two|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|        1|      two|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|        1|      two|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|        1|      two|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|        1|      two|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|        1|      two|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|        1|      two|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|        1|      two|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|        1|      two|\n",
      "|         11|   David Park| 38|65000.0|13000.0|        1|      two|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|        1|      two|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|        1|      two|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|        1|      two|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|        1|      two|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|        1|      two|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|        1|      two|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|        1|      two|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|        1|      two|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|        1|      two|\n",
      "+-----------+-------------+---+-------+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_new_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrame where tax > 10000, along with LIMIT to 5 rows\n",
    "\n",
    "emp_taxed.where(\"tax > 10000\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+------+\n",
      "|employee_id|         name|age| salary|    tax| bonus|\n",
      "+-----------+-------------+---+-------+-------+------+\n",
      "|          1|     John Doe| 30|50000.0|10000.0|5000.0|\n",
      "|          2|   Jane Smith| 25|45000.0| 9000.0|4500.0|\n",
      "|          3|    Bob Brown| 35|55000.0|11000.0|5500.0|\n",
      "|          4|    Alice Lee| 28|48000.0| 9600.0|4800.0|\n",
      "|          5|    Jack Chan| 40|60000.0|12000.0|6000.0|\n",
      "|          6|    Jill Wong| 32|52000.0|10400.0|5200.0|\n",
      "|          7|James Johnson| 42|70000.0|14000.0|7000.0|\n",
      "|          8|     Kate Kim| 29|51000.0|10200.0|5100.0|\n",
      "|          9|      Tom Tan| 33|58000.0|11600.0|5800.0|\n",
      "|         10|     Lisa Lee| 27|47000.0| 9400.0|4700.0|\n",
      "|         11|   David Park| 38|65000.0|13000.0|6500.0|\n",
      "|         12|   Susan Chen| 31|54000.0|10800.0|5400.0|\n",
      "|         13|    Brian Kim| 45|75000.0|15000.0|7500.0|\n",
      "|         14|    Emily Lee| 26|46000.0| 9200.0|4600.0|\n",
      "|         15|  Michael Lee| 37|63000.0|12600.0|6300.0|\n",
      "|         16|  Kelly Zhang| 30|49000.0| 9800.0|4900.0|\n",
      "|         17|  George Wang| 34|57000.0|11400.0|5700.0|\n",
      "|         18|    Nancy Liu| 29|50000.0|10000.0|5000.0|\n",
      "|         19|  Steven Chen| 36|62000.0|12400.0|6200.0|\n",
      "|         20|    Grace Kim| 32|53000.0|10600.0|5300.0|\n",
      "+-----------+-------------+---+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bonus: Adding multiple columns to the dataframe at once\n",
    "\n",
    "columns = {\n",
    "    'tax': col('salary') * 0.2,\n",
    "    'bonus': col('salary') * 0.1\n",
    "}\n",
    "\n",
    "emp_casted.withColumns(columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3e6699c11a7b:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark-intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc63f7ecc50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"String & Dates\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+----------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|         M|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|         F|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|         M|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|         F|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|         M|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|         F|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|         M|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|         F|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|         M|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|         F|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|         M|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|         F|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|         M|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|         F|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|         M|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|         F|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|         M|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|         F|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|         M|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|         F|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a \"Case\" column to the DataFrame based on conditions\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "emp.withColumn('new_gender', when(col('gender') == 'Male', 'M').when(col('gender') == 'Female', 'F').otherwise(None)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+-------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|     new_name|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+-------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|     Zohn Doe|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|   Zane Smith|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|    Bob Brown|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|    Alice Lee|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|    Zack Chan|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|    Zill Wong|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|Zames Zohnson|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|     Kate Kim|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|      Tom Tan|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|     Lisa Lee|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|   David Park|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|   Susan Chen|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|    Brian Kim|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|    Emily Lee|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|  Michael Lee|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|  Kelly Zhang|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|  George Wang|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|    Nancy Liu|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|  Steven Chen|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|    Grace Kim|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace in Strings\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "emp.withColumn(\"new_name\", regexp_replace(\"name\", \"J\", \"Z\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Timestamp (String) type column to Date type\n",
    "\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "emp.withColumn(\"hire_date\", to_date(col(\"hire_date\"), 'yyyy-MM-dd')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+------------+--------------------------+\n",
      "|employee_id|department_id|name         |age|gender|salary|hire_date          |current_date|current_timestamp         |\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+------------+--------------------------+\n",
      "|1          |101          |John Doe     |30 |Male  |50000 |2015-01-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|2          |101          |Jane Smith   |25 |Female|45000 |2016-02-15 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|3          |102          |Bob Brown    |35 |Male  |55000 |2014-05-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|4          |102          |Alice Lee    |28 |Female|48000 |2017-09-30 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|5          |103          |Jack Chan    |40 |Male  |60000 |2013-04-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|6          |103          |Jill Wong    |32 |Female|52000 |2018-07-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|7          |101          |James Johnson|42 |Male  |70000 |2012-03-15 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|8          |102          |Kate Kim     |29 |Female|51000 |2019-10-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|9          |103          |Tom Tan      |33 |Male  |58000 |2016-06-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|10         |104          |Lisa Lee     |27 |Female|47000 |2018-08-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|11         |104          |David Park   |38 |Male  |65000 |2015-11-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|12         |105          |Susan Chen   |31 |Female|54000 |2017-02-15 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|13         |106          |Brian Kim    |45 |Male  |75000 |2011-07-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|14         |107          |Emily Lee    |26 |Female|46000 |2019-01-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|15         |106          |Michael Lee  |37 |Male  |63000 |2014-09-30 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|16         |107          |Kelly Zhang  |30 |Female|49000 |2018-04-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|17         |105          |George Wang  |34 |Male  |57000 |2016-03-15 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|18         |104          |Nancy Liu    |29 |Female|50000 |2017-06-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|19         |103          |Steven Chen  |36 |Male  |62000 |2015-08-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "|20         |102          |Grace Kim    |32 |Female|53000 |2018-11-01 00:00:00|2025-04-30  |2025-04-30 02:52:20.972595|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add Current Date and Timestamp columns\n",
    "\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "\n",
    "columns = {\n",
    "    \"current_date\": current_date(),\n",
    "    \"current_timestamp\": current_timestamp()\n",
    "}\n",
    "\n",
    "emp.withColumns(columns).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with null values in a column\n",
    "\n",
    "temp = emp.withColumn(\"gender\", when(col(\"name\") == \"Nancy Liu\", None).otherwise(col(\"gender\")))\n",
    "temp.na.drop().show()\n",
    "\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+-------+------+-------------------+\n",
      "|employee_id|department_id|         name|age| gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+-------+------+-------------------+\n",
      "|          1|          101|     John Doe| 30|   Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25| Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|   Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28| Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|   Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32| Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|   Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29| Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|   Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27| Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|   Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31| Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|   Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26| Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|   Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30| Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|   Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Unknown| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|   Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32| Female| 53000|2018-11-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+-------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix null values with coalesce\n",
    "from pyspark.sql.functions import coalesce, lit\n",
    "\n",
    "temp = emp.withColumn(\"gender\", when(col(\"name\") == \"Nancy Liu\", None).otherwise(col(\"gender\")))\n",
    "\n",
    "temp.withColumn(\"gender\", coalesce(col(\"gender\"), lit(\"Unknown\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+---------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|hire_year|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+---------+\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|     2015|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|     2016|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|     2014|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|     2017|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|     2013|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|     2018|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|     2012|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|     2019|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|     2016|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|     2018|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|     2015|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|     2017|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|     2011|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|     2019|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|     2014|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|     2018|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|     2016|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|     2017|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|     2015|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|     2018|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert date/timestamp into string and extract information from it\n",
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "emp.withColumn(\"hire_year\", date_format(col(\"hire_date\"), \"yyyy\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort, Union & Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert all columns to string type\n",
    "\n",
    "emp_str = emp.select([col(c).cast(\"string\") for c in emp.columns])\n",
    "emp_str.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into 2 parts\n",
    "\n",
    "emp_str1 = emp_str.filter(emp.employee_id < 11)\n",
    "emp_str2 = emp_str.filter(emp.employee_id > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Union and Union All (remove duplicates)\n",
    "# ! The columns must be in the same order and have the same data types\n",
    "# ? UnionByName can used when the column names are different but data types are same\n",
    "\n",
    "emp_str2.union(emp_str1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting the dataframe\n",
    "\n",
    "from pyspark.sql.functions import asc, desc\n",
    "\n",
    "emp.orderBy(desc(\"salary\")).show(5)\n",
    "\n",
    "emp.orderBy(asc(\"hire_date\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+\n",
      "|department_id|dept_count|dept_pay|\n",
      "+-------------+----------+--------+\n",
      "|          103|         4|  232000|\n",
      "|          102|         4|  207000|\n",
      "|          101|         3|  165000|\n",
      "|          104|         3|  162000|\n",
      "|          106|         2|  138000|\n",
      "|          105|         2|  111000|\n",
      "|          107|         2|   95000|\n",
      "+-------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation functions\n",
    "from pyspark.sql.functions import count, sum, avg, max, min\n",
    "\n",
    "emp.groupBy(\"department_id\").agg(count(\"employee_id\").alias(\"dept_count\"), sum(\"salary\").alias(\"dept_pay\")).orderBy(desc(\"dept_pay\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|department_id|avg_dept_salary|\n",
      "+-------------+---------------+\n",
      "|          101|        55000.0|\n",
      "|          103|        58000.0|\n",
      "|          102|        51750.0|\n",
      "|          105|        55500.0|\n",
      "|          106|        69000.0|\n",
      "|          104|        54000.0|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.groupby(\"department_id\").agg(avg(\"salary\").alias(\"avg_dept_salary\")).where(col(\"avg_dept_salary\") > 50000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Data and Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get unique data from the dataframe\n",
    "\n",
    "emp.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|department_id|\n",
      "+-------------+\n",
      "|          101|\n",
      "|          103|\n",
      "|          107|\n",
      "|          102|\n",
      "|          105|\n",
      "|          106|\n",
      "|          104|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.select('department_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+-------------------+---------------+\n",
      "|employee_id|department_id|         name|age|gender|salary|          hire_date|max_dept_salary|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+---------------+\n",
      "|          7|          101|James Johnson| 42|  Male| 70000|2012-03-15 00:00:00|          70000|\n",
      "|          1|          101|     John Doe| 30|  Male| 50000|2015-01-01 00:00:00|          70000|\n",
      "|          2|          101|   Jane Smith| 25|Female| 45000|2016-02-15 00:00:00|          70000|\n",
      "|          3|          102|    Bob Brown| 35|  Male| 55000|2014-05-01 00:00:00|          55000|\n",
      "|         20|          102|    Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|          55000|\n",
      "|          8|          102|     Kate Kim| 29|Female| 51000|2019-10-01 00:00:00|          55000|\n",
      "|          4|          102|    Alice Lee| 28|Female| 48000|2017-09-30 00:00:00|          55000|\n",
      "|         19|          103|  Steven Chen| 36|  Male| 62000|2015-08-01 00:00:00|          62000|\n",
      "|          5|          103|    Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|          62000|\n",
      "|          9|          103|      Tom Tan| 33|  Male| 58000|2016-06-01 00:00:00|          62000|\n",
      "|          6|          103|    Jill Wong| 32|Female| 52000|2018-07-01 00:00:00|          62000|\n",
      "|         11|          104|   David Park| 38|  Male| 65000|2015-11-01 00:00:00|          65000|\n",
      "|         18|          104|    Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|          65000|\n",
      "|         10|          104|     Lisa Lee| 27|Female| 47000|2018-08-01 00:00:00|          65000|\n",
      "|         17|          105|  George Wang| 34|  Male| 57000|2016-03-15 00:00:00|          57000|\n",
      "|         12|          105|   Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|          57000|\n",
      "|         13|          106|    Brian Kim| 45|  Male| 75000|2011-07-01 00:00:00|          75000|\n",
      "|         15|          106|  Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|          75000|\n",
      "|         16|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01 00:00:00|          49000|\n",
      "|         14|          107|    Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|          49000|\n",
      "+-----------+-------------+-------------+---+------+------+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Window functions\n",
    "# ? Allows to compute values based on a \"window\" of rows without collapsing them into a single row, unlike groupBy()\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import max, col, desc\n",
    "\n",
    "window_spec = Window.partitionBy(\"department_id\").orderBy(desc(\"salary\"))\n",
    "max_func = max(col(\"salary\")).over(window_spec)\n",
    "\n",
    "emp.withColumn(\"max_dept_salary\", max_func).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+---+------+------+-------------------+----+\n",
      "|employee_id|department_id|       name|age|gender|salary|          hire_date|rank|\n",
      "+-----------+-------------+-----------+---+------+------+-------------------+----+\n",
      "|          1|          101|   John Doe| 30|  Male| 50000|2015-01-01 00:00:00|   2|\n",
      "|         20|          102|  Grace Kim| 32|Female| 53000|2018-11-01 00:00:00|   2|\n",
      "|          5|          103|  Jack Chan| 40|  Male| 60000|2013-04-01 00:00:00|   2|\n",
      "|         18|          104|  Nancy Liu| 29|Female| 50000|2017-06-01 00:00:00|   2|\n",
      "|         12|          105| Susan Chen| 31|Female| 54000|2017-02-15 00:00:00|   2|\n",
      "|         15|          106|Michael Lee| 37|  Male| 63000|2014-09-30 00:00:00|   2|\n",
      "|         14|          107|  Emily Lee| 26|Female| 46000|2019-01-01 00:00:00|   2|\n",
      "+-----------+-------------+-----------+---+------+------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 2nd highest salary in each department\n",
    "\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "rank_spec = Window.partitionBy(\"department_id\").orderBy(desc(\"salary\"))\n",
    "rank_func = rank().over(rank_spec)\n",
    "\n",
    "emp.withColumn(\"rank\", rank_func).filter(col(\"rank\") == 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
